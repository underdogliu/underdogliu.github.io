---
layout: post
title: A little bit on speech frontend 
description: In short, we may want something in the middle.
nav: true
---

-------------------
### Some background (intuitively)
Since I started my PhD with my supervisors, I have been involved mainly on feature analysis - both of my supervisors are big fan of frontend stuff for in speech pipeline. Such 'frontend' can mean different things under different context. Allow me to give some examples.

Most typically, in supervised speech processing tasks like speech recognition and speaker verification etc, usually we regard all steps between loading speech files and creating acoustic representations for training the classification model as 'frontend'. In this context, we create 'acoustic features' from the signal via some framing, domain transformation and warping steps. I believe that every individual who works in speech processing have heard Mel frequency cepstral coeffcients (MFCCs) at the very beginning of 

-------------------
### Let's review some good, static frontends


-------------------
### Totally neural solution? --my critisism on SincNet


-------------------
### Something in between might be the future...


-------------

UNDERDOG 

2021-03-01

Nancy, 23C, Sunny

[1] [Teacher-student training for text-independent speaker recognition](https://ieeexplore.ieee.org/document/8639564), Raymond W. M. Ng, Xuechen Liu, and Pawel Swietojanski, IEEE SLT 2018, Athens, Greece